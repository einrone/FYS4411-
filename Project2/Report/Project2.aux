\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{Broecker2017}
\citation{Botu2015}
\citation{Carleo602}
\citation{0305-4470-27-3-040}
\citation{PhysRevB.84.115302}
\citation{Griffiths2004}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{3}{section.1}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Theory}{3}{section.2}}
\newlabel{sec:Theory}{{2}{3}{Theory}{section.2}{}}
\newlabel{sec:Theory@cref}{{[section][2][]2}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}The Hamiltonian}{3}{subsection.2.1}}
\newlabel{eq:Hamiltonian}{{1}{3}{The Hamiltonian}{equation.2.1}{}}
\newlabel{eq:Hamiltonian@cref}{{[equation][1][]1}{3}}
\newlabel{eq:time_depenedent_schrodinger}{{2}{3}{The Hamiltonian}{equation.2.2}{}}
\newlabel{eq:time_depenedent_schrodinger@cref}{{[equation][2][]2}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Analytic solution}{3}{subsection.2.2}}
\citation{0305-4470-27-3-040}
\citation{PhysRevB.84.115302}
\citation{Griffiths2004}
\citation{Carleo602}
\citation{Carleo602}
\citation{Hinton2010}
\newlabel{eq:Ground-state-energy}{{4}{4}{Analytic solution}{equation.2.4}{}}
\newlabel{eq:Ground-state-energy@cref}{{[equation][4][]4}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}The variational principle}{4}{subsection.2.3}}
\newlabel{eq:Variational_Principle}{{5}{4}{The variational principle}{equation.2.5}{}}
\newlabel{eq:Variational_Principle@cref}{{[equation][5][]5}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Neural-network quantum states and Restricted Boltzmann Machines}{4}{subsection.2.4}}
\citation{Wang2014}
\citation{Wang2014}
\citation{Hjorth-Jensen2018}
\citation{Hjorth-Jensen2015}
\newlabel{eq:Wavefunction}{{9}{5}{Neural-network quantum states and Restricted Boltzmann Machines}{equation.2.9}{}}
\newlabel{eq:Wavefunction@cref}{{[equation][9][]9}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Variational Monte Carlo methods}{5}{subsection.2.5}}
\newlabel{eq:Local_energy}{{11}{5}{Variational Monte Carlo methods}{equation.2.11}{}}
\newlabel{eq:Local_energy@cref}{{[equation][11][]11}{5}}
\citation{Hjorth-Jensen2015}
\citation{Hjorth-Jensen2015}
\newlabel{eq:energy_in_state_space}{{12}{6}{Variational Monte Carlo methods}{equation.2.12}{}}
\newlabel{eq:energy_in_state_space@cref}{{[equation][12][]12}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6}The local energy}{6}{subsection.2.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7}Sampling the position space}{6}{subsection.2.7}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.7.1}The Metropolis algorithm}{6}{subsubsection.2.7.1}}
\newlabel{eq:metropolis_algorithm_step_size}{{14}{6}{The Metropolis algorithm}{equation.2.14}{}}
\newlabel{eq:metropolis_algorithm_step_size@cref}{{[equation][14][]14}{6}}
\newlabel{eq:transition_probability}{{15}{6}{The Metropolis algorithm}{equation.2.15}{}}
\newlabel{eq:transition_probability@cref}{{[equation][15][]15}{6}}
\citation{Hjorth-Jensen2015}
\citation{Wang2014}
\citation{Hjorth-Jensen2018}
\citation{Hjorth-Jensen2018}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.7.2}The Metropolis-Hasting alogrithm/importance sampling}{7}{subsubsection.2.7.2}}
\newlabel{eq:quantum_force}{{17}{7}{The Metropolis-Hasting alogrithm/importance sampling}{equation.2.17}{}}
\newlabel{eq:quantum_force@cref}{{[equation][17][]17}{7}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.7.3}Gibbs Sampling}{7}{subsubsection.2.7.3}}
\newlabel{eq:wavefunction_Gibbs}{{20}{7}{Gibbs Sampling}{equation.2.20}{}}
\newlabel{eq:wavefunction_Gibbs@cref}{{[equation][20][]20}{7}}
\newlabel{eq:Marginal_distribution_H}{{21}{7}{Gibbs Sampling}{equation.2.21}{}}
\newlabel{eq:Marginal_distribution_H@cref}{{[equation][21][]21}{7}}
\citation{Heinsen2018}
\citation{Heinsen2018}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.8}Optimizing our wavefunction in parameter space}{8}{subsection.2.8}}
\newlabel{eq:Minimization_theory}{{23}{8}{Optimizing our wavefunction in parameter space}{equation.2.23}{}}
\newlabel{eq:Minimization_theory@cref}{{[equation][23][]23}{8}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Methods}{8}{section.3}}
\newlabel{Method_section}{{3}{8}{Methods}{section.3}{}}
\newlabel{Method_section@cref}{{[section][3][]3}{8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}An overview of the structure of our program}{8}{subsection.3.1}}
\@writefile{toc}{\contentsline {paragraph}{\texttt  {main.cpp}}{8}{section*.2}}
\@writefile{toc}{\contentsline {paragraph}{\texttt  {simulation.cpp}}{8}{section*.3}}
\citation{Hjorth-Jensen2015}
\@writefile{toc}{\contentsline {paragraph}{\texttt  {system.cpp}}{9}{section*.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Initializing our system}{9}{subsection.3.2}}
\newlabel{sec:Initialization}{{3.2}{9}{Initializing our system}{subsection.3.2}{}}
\newlabel{sec:Initialization@cref}{{[subsection][2][3]3.2}{9}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.1}Initializing the position}{9}{subsubsection.3.2.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.2}Initializing the parameters}{9}{subsubsection.3.2.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.3}Initializing the simulation}{9}{subsubsection.3.2.3}}
\citation{Hjorth-Jensen2015}
\citation{Jonsson2018}
\citation{Heinsen2018}
\citation{Jonsson2018}
\citation{0305-4470-27-3-040}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Proposing a new position}{10}{subsection.3.3}}
\newlabel{sec:met_propose_new_position}{{3.3}{10}{Proposing a new position}{subsection.3.3}{}}
\newlabel{sec:met_propose_new_position@cref}{{[subsection][3][3]3.3}{10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Implementing the optimization of the biases and the weights}{10}{subsection.3.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}The errors in our energy}{10}{subsection.3.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6}Tuning the parameters}{10}{subsection.3.6}}
\newlabel{sec:met_tuning_parameters}{{3.6}{10}{Tuning the parameters}{subsection.3.6}{}}
\newlabel{sec:met_tuning_parameters@cref}{{[subsection][6][3]3.6}{10}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.6.1}Tuning the step size, $\boldsymbol  {dx}$}{11}{subsubsection.3.6.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.6.2}Tuning the learning rate, $\boldsymbol  {\gamma }$ and the number of hidden nodes, $\boldsymbol  {N}$}{11}{subsubsection.3.6.2}}
\newlabel{sec:Met_tuning_gamma_N}{{3.6.2}{11}{Tuning the learning rate, $\boldsymbol {\gamma }$ and the number of hidden nodes, $\boldsymbol {N}$}{subsubsection.3.6.2}{}}
\newlabel{sec:Met_tuning_gamma_N@cref}{{[subsubsection][2][3,6]3.6.2}{11}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.6.3}Choosing the number of Monte Carlo steps}{11}{subsubsection.3.6.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.7}Benchmarking our results}{11}{subsection.3.7}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Results}{11}{section.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Tuning our neural network quantum state in the simplest system}{11}{subsection.4.1}}
\newlabel{sec:res_tuning_parameters_noninteracting}{{4.1}{11}{Tuning our neural network quantum state in the simplest system}{subsection.4.1}{}}
\newlabel{sec:res_tuning_parameters_noninteracting@cref}{{[subsection][1][4]4.1}{11}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.1}Tuning $\boldsymbol  {dx}$}{12}{subsubsection.4.1.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Plot of the mean energy and corresponding acceptance rate for various values of $dx$, using $1$ particle in $1$ dimension and $2^{21}/10$ Monte Carlo steps. This was produced using brute-force Metropolis sampling with $N=2$ and $\gamma =0.3$. Errors were estimated using blocking, but are too small to be visible.\relax }}{12}{figure.caption.5}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:results_benchmark_no_importance}{{1}{12}{Plot of the mean energy and corresponding acceptance rate for various values of $dx$, using $1$ particle in $1$ dimension and $2^{21}/10$ Monte Carlo steps. This was produced using brute-force Metropolis sampling with $N=2$ and $\gamma =0.3$. Errors were estimated using blocking, but are too small to be visible.\relax }{figure.caption.5}{}}
\newlabel{fig:results_benchmark_no_importance@cref}{{[figure][1][]1}{12}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Same as figure \ref  {fig:results_benchmark_no_importance}, but using importance sampling\relax }}{13}{figure.caption.6}}
\newlabel{fig:results_benchmark_importance}{{2}{13}{Same as figure \ref {fig:results_benchmark_no_importance}, but using importance sampling\relax }{figure.caption.6}{}}
\newlabel{fig:results_benchmark_importance@cref}{{[figure][2][]2}{13}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.2}Tuning $\boldsymbol  {N}$ and $\boldsymbol  {\gamma }$}{14}{subsubsection.4.1.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Plot of the absolute value of the gradient and the energy as a function of iterations for various values of $N$ and $\gamma $. This was performed using brute-force Metropolis sampling, using $1$ particle in $1$ dimension and $2^{21}/10$ Monte Carlo cycles. We used $dx=0.5$. Our convergence tolerance $\epsilon = 10^{-5}$, and we used a maximum of $100$ iterations.\relax }}{14}{figure.caption.7}}
\newlabel{fig:step_size_and_N_standard}{{3}{14}{Plot of the absolute value of the gradient and the energy as a function of iterations for various values of $N$ and $\gamma $. This was performed using brute-force Metropolis sampling, using $1$ particle in $1$ dimension and $2^{21}/10$ Monte Carlo cycles. We used $dx=0.5$. Our convergence tolerance $\epsilon = 10^{-5}$, and we used a maximum of $100$ iterations.\relax }{figure.caption.7}{}}
\newlabel{fig:step_size_and_N_standard@cref}{{[figure][3][]3}{14}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Same as figure \ref  {fig:step_size_and_N_standard}, but using importance sampling.\relax }}{15}{figure.caption.8}}
\newlabel{fig:step_size_and_N_importance}{{4}{15}{Same as figure \ref {fig:step_size_and_N_standard}, but using importance sampling.\relax }{figure.caption.8}{}}
\newlabel{fig:step_size_and_N_importance@cref}{{[figure][4][]4}{15}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Same as figure \ref  {fig:step_size_and_N_standard} but using Gibbs sampling\relax }}{16}{figure.caption.9}}
\newlabel{fig:step_size_and_N_gibbs}{{5}{16}{Same as figure \ref {fig:step_size_and_N_standard} but using Gibbs sampling\relax }{figure.caption.9}{}}
\newlabel{fig:step_size_and_N_gibbs@cref}{{[figure][5][]5}{16}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Tuning our neural network quantum state in the interacting system}{16}{subsection.4.2}}
\newlabel{sec:res_tuning_parameters_interacting}{{4.2}{16}{Tuning our neural network quantum state in the interacting system}{subsection.4.2}{}}
\newlabel{sec:res_tuning_parameters_interacting@cref}{{[subsection][2][4]4.2}{16}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.1}Tuning $\boldsymbol  {dx}$}{16}{subsubsection.4.2.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Plot of the mean energy and corresponding acceptance rate for various values of $dx$ using $2$ particles in $2$ dimensions and $2^{21}/10$ Monte Carlo steps. This was produced using brute-force Metropolis sampling with $N=2 and \gamma =0.3$.\relax }}{17}{figure.caption.10}}
\newlabel{fig:results_benchmark_no_importance_interacting}{{6}{17}{Plot of the mean energy and corresponding acceptance rate for various values of $dx$ using $2$ particles in $2$ dimensions and $2^{21}/10$ Monte Carlo steps. This was produced using brute-force Metropolis sampling with $N=2 and \gamma =0.3$.\relax }{figure.caption.10}{}}
\newlabel{fig:results_benchmark_no_importance_interacting@cref}{{[figure][6][]6}{17}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Same as figure \ref  {fig:results_benchmark_no_importance_interacting} but with importance sampling\relax }}{18}{figure.caption.11}}
\newlabel{fig:results_benchmark_importance_interacting}{{7}{18}{Same as figure \ref {fig:results_benchmark_no_importance_interacting} but with importance sampling\relax }{figure.caption.11}{}}
\newlabel{fig:results_benchmark_importance_interacting@cref}{{[figure][7][]7}{18}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.2}Tuning $\boldsymbol  {N}$ and $\boldsymbol  {\gamma }$}{19}{subsubsection.4.2.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Plot of the absolute value of the gradient and the energy as a function of iterations for various values of $N$ and $\gamma $. This was performed using brute-force Metropolis sampling, using $2$ particles in $2$ dimensions and $20^{21}/10$ Monte Carlo cycles. We here used $dx=0.1$. Our convergence tolerance $\epsilon = 10^{-5}$, and we used a maximum of $100$ iterations.\relax }}{19}{figure.caption.12}}
\newlabel{fig:step_size_and_N_interacting}{{8}{19}{Plot of the absolute value of the gradient and the energy as a function of iterations for various values of $N$ and $\gamma $. This was performed using brute-force Metropolis sampling, using $2$ particles in $2$ dimensions and $20^{21}/10$ Monte Carlo cycles. We here used $dx=0.1$. Our convergence tolerance $\epsilon = 10^{-5}$, and we used a maximum of $100$ iterations.\relax }{figure.caption.12}{}}
\newlabel{fig:step_size_and_N_interacting@cref}{{[figure][8][]8}{19}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Same as figure \ref  {fig:step_size_and_N_interacting}, but using importance sampling and therefore $dx=0.1$.\relax }}{20}{figure.caption.13}}
\newlabel{fig:step_size_and_N_importance_interacting}{{9}{20}{Same as figure \ref {fig:step_size_and_N_interacting}, but using importance sampling and therefore $dx=0.1$.\relax }{figure.caption.13}{}}
\newlabel{fig:step_size_and_N_importance_interacting@cref}{{[figure][9][]9}{20}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Same as figure \ref  {fig:step_size_and_N_interacting} but using Gibbs sampling.\relax }}{21}{figure.caption.14}}
\newlabel{fig:step_size_and_N_gibbs_interacting}{{10}{21}{Same as figure \ref {fig:step_size_and_N_interacting} but using Gibbs sampling.\relax }{figure.caption.14}{}}
\newlabel{fig:step_size_and_N_gibbs_interacting@cref}{{[figure][10][]10}{21}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Results for the tuned system}{22}{subsection.4.3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.1}The noninteracting system}{22}{subsubsection.4.3.1}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Results for the noninteracting system with $1$ particle, using the tuned parameters described in section \ref  {sec:res_tuning_parameters_noninteracting}. We use $2^{21}$ Monte Carlo cycles, and a convergence tolerance $\epsilon $ of $10^{-3}$ with a maximum of $100$ iterations. The error is estimated using the blocking method.\relax }}{22}{table.caption.15}}
\newlabel{tab:noninteracting_results}{{1}{22}{Results for the noninteracting system with $1$ particle, using the tuned parameters described in section \ref {sec:res_tuning_parameters_noninteracting}. We use $2^{21}$ Monte Carlo cycles, and a convergence tolerance $\epsilon $ of $10^{-3}$ with a maximum of $100$ iterations. The error is estimated using the blocking method.\relax }{table.caption.15}{}}
\newlabel{tab:noninteracting_results@cref}{{[table][1][]1}{22}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.2}The interacting system}{22}{subsubsection.4.3.2}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Results for the interacting system in two dimensions, using the parameter tunings from section \ref  {sec:res_tuning_parameters_interacting}. We used $2^{21}$ Monte Carlo cycles, and a convergence tolerance $\epsilon $ of $10^{-3}$ with a maximum of $100$ iterations. The error was estimated using the blocking method.\relax }}{22}{table.caption.16}}
\newlabel{tab:interacting_results}{{2}{22}{Results for the interacting system in two dimensions, using the parameter tunings from section \ref {sec:res_tuning_parameters_interacting}. We used $2^{21}$ Monte Carlo cycles, and a convergence tolerance $\epsilon $ of $10^{-3}$ with a maximum of $100$ iterations. The error was estimated using the blocking method.\relax }{table.caption.16}{}}
\newlabel{tab:interacting_results@cref}{{[table][2][]2}{22}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Discussion}{23}{section.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Tuning the parameters}{23}{subsection.5.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.1}The noninteracting case}{23}{subsubsection.5.1.1}}
\newlabel{sec:tuning_parameters_noninteracting}{{5.1.1}{23}{The noninteracting case}{subsubsection.5.1.1}{}}
\newlabel{sec:tuning_parameters_noninteracting@cref}{{[subsubsection][1][5,1]5.1.1}{23}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Chosen parameters in the noninteracting case\relax }}{23}{table.caption.17}}
\newlabel{tab:chosen_parameters_noninteracting}{{3}{23}{Chosen parameters in the noninteracting case\relax }{table.caption.17}{}}
\newlabel{tab:chosen_parameters_noninteracting@cref}{{[table][3][]3}{23}}
\@writefile{toc}{\contentsline {paragraph}{The step size}{23}{section*.18}}
\@writefile{toc}{\contentsline {paragraph}{The learning rate and the number of hidden nodes}{23}{section*.19}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.2}The interacting case}{24}{subsubsection.5.1.2}}
\newlabel{sec:tuning_parameters_interacting}{{5.1.2}{24}{The interacting case}{subsubsection.5.1.2}{}}
\newlabel{sec:tuning_parameters_interacting@cref}{{[subsubsection][2][5,1]5.1.2}{24}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Chosen parameters in the noninteracting case\relax }}{24}{table.caption.20}}
\newlabel{tab:chosen_parameters_interacting}{{4}{24}{Chosen parameters in the noninteracting case\relax }{table.caption.20}{}}
\newlabel{tab:chosen_parameters_interacting@cref}{{[table][4][]4}{24}}
\@writefile{toc}{\contentsline {paragraph}{The step size}{24}{section*.21}}
\@writefile{toc}{\contentsline {paragraph}{The learning rate and the number of hidden nodes}{24}{section*.22}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Choosing the initial distributions}{24}{subsection.5.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Results with the tuned parameters}{25}{subsection.5.3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.1}The noninteracting case}{25}{subsubsection.5.3.1}}
\newlabel{sec:disc_result_noninteracting}{{5.3.1}{25}{The noninteracting case}{subsubsection.5.3.1}{}}
\newlabel{sec:disc_result_noninteracting@cref}{{[subsubsection][1][5,3]5.3.1}{25}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.2}The interacting case}{25}{subsubsection.5.3.2}}
\newlabel{sec:disc_result_interacting}{{5.3.2}{25}{The interacting case}{subsubsection.5.3.2}{}}
\newlabel{sec:disc_result_interacting@cref}{{[subsubsection][2][5,3]5.3.2}{25}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusion}{25}{section.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Conclusion}{25}{subsection.6.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Outlook}{26}{subsection.6.2}}
\bibstyle{apalike}
\bibdata{Project2}
\bibcite{Botu2015}{Botu and Ramprasad, 2015}
\bibcite{Broecker2017}{Broecker et\nobreakspace  {}al., 2017}
\bibcite{Carleo602}{Carleo and Troyer, 2017}
\bibcite{Griffiths2004}{Griffiths, 2004}
\bibcite{Heinsen2018}{Heinesen et\nobreakspace  {}al., 2018}
\bibcite{Hinton2010}{Hinton, 2010}
\bibcite{Hjorth-Jensen2015}{Hjorth-Jensen, 2015}
\bibcite{Hjorth-Jensen2018}{Hjorth-Jensen, 2018}
\bibcite{Jonsson2018}{Jonsson, 2018}
\bibcite{PhysRevB.84.115302}{{Pedersen Lohne} et\nobreakspace  {}al., 2011}
\bibcite{0305-4470-27-3-040}{Taut, 1994}
\bibcite{Wang2014}{Wang et\nobreakspace  {}al., 2014}
\@writefile{toc}{\contentsline {section}{Appendices}{28}{section*.24}}
\@writefile{toc}{\contentsline {section}{\numberline {A}Finding the derivatives}{28}{Appendix.a.A}}
\newlabel{ap:finding_derivatives}{{A}{28}{Finding the derivatives}{Appendix.a.A}{}}
\newlabel{ap:finding_derivatives@cref}{{[section][1][]A}{28}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1}The local energy}{28}{subsection.a.A.1}}
\newlabel{ap:local_energy}{{A.1}{28}{The local energy}{subsection.a.A.1}{}}
\newlabel{ap:local_energy@cref}{{[subsection][1][1]A.1}{28}}
\newlabel{eq:ap_local_energy}{{29}{28}{The local energy}{equation.a.A.29}{}}
\newlabel{eq:ap_local_energy@cref}{{[equation][29][]29}{28}}
\newlabel{eq:log_expression_for_trial_wavefunction}{{31}{28}{The local energy}{equation.a.A.31}{}}
\newlabel{eq:log_expression_for_trial_wavefunction@cref}{{[equation][31][]31}{28}}
\newlabel{eq:logarithm_of_wavefunction}{{32}{28}{The local energy}{equation.a.A.32}{}}
\newlabel{eq:logarithm_of_wavefunction@cref}{{[equation][32][]32}{28}}
\newlabel{eq:first_derivative_log_psi}{{33}{28}{The local energy}{equation.a.A.33}{}}
\newlabel{eq:first_derivative_log_psi@cref}{{[equation][33][]33}{28}}
\newlabel{eq:second_derivative_log_psi}{{34}{28}{The local energy}{equation.a.A.34}{}}
\newlabel{eq:second_derivative_log_psi@cref}{{[equation][34][]34}{28}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.2}The derivatives with respect to the parameters}{28}{subsection.a.A.2}}
\newlabel{ap:derivative_parameters}{{A.2}{28}{The derivatives with respect to the parameters}{subsection.a.A.2}{}}
\newlabel{ap:derivative_parameters@cref}{{[subsection][2][1]A.2}{28}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.3}The derivatives with Gibbs sampling}{29}{subsection.a.A.3}}
\newlabel{ap:derivative_gibbs}{{A.3}{29}{The derivatives with Gibbs sampling}{subsection.a.A.3}{}}
\newlabel{ap:derivative_gibbs@cref}{{[subsection][3][1]A.3}{29}}
\@writefile{toc}{\contentsline {section}{\numberline {B}Deriving the spin of the ground state wavefunction}{29}{Appendix.a.B}}
\newlabel{ap:Derivative_spin}{{B}{29}{Deriving the spin of the ground state wavefunction}{Appendix.a.B}{}}
\newlabel{ap:Derivative_spin@cref}{{[section][2][]B}{29}}
